{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503585de-7619-47c7-a627-872789c23f1e",
   "metadata": {},
   "source": [
    "# Product Insight Validation Using LLMs üîç\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebooks aims to evaluate different prompting strategies for validating product insights using a Large Language Model (LLM). The goal is to determine the most effective prompting approach for distinguishing between valid and invalid insights based on predefined criteria.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "- **Compare Prompting Strategies:** Test multiple prompts and strategies to determine which yields the best classification results.\n",
    "- **Evaluate Performance:** Measure the effectiveness of each strategy using precision, recall, and F1 score.\n",
    "- **Cross-Validation Approach:** Utilize a labeled dataset containing:\n",
    "  - **True Positives (TP):** Correctly identified valid insights.\n",
    "  - **True Negatives (TN):** Correctly identified invalid insights.\n",
    "  - **False Positives (FP):** Incorrectly marked invalid insights as valid.\n",
    "  - **False Negatives (FN):** Incorrectly marked valid insights as invalid.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "1. **Load Product Insights**  \n",
    "   - Import CSV files containing product insights for validation.\n",
    "\n",
    "2. **Apply LLM-Based Validation**  \n",
    "   - Use different prompts and prompting strategies to classify insights.\n",
    "\n",
    "3. **Evaluate Performance**  \n",
    "   - Compute precision, recall, and F1 score to assess classification accuracy.\n",
    "   - Compare the effectiveness of different strategies based on their performance metrics.\n",
    "\n",
    "4. **Optimize for Accuracy**  \n",
    "   - Identify the best-performing prompt and strategy for product insight validation.\n",
    "\n",
    "## Tech Stack\n",
    "\n",
    "- **LLM Provider:** Azure OpenAI  \n",
    "- **Model:** ChatGPT 4.0  \n",
    "- **Data Processing:** Python (pandas, numpy)  \n",
    "- **Evaluation Metrics:** precision, recall, F1 score  \n",
    "\n",
    "## Expected Outcomes\n",
    "\n",
    "- A clear understanding of which prompting strategy yields the best results.\n",
    "- A methodology/workflow that can be iteratively improved and scaled for future product insight validation tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b6a5a9dc-0cbe-4f4c-bb91-51722615fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's import the packages we will need for this project\n",
    "\n",
    "import requests # for connecting with Azure Open AI\n",
    "import json # for parsing responses\n",
    "import csv # for data processing\n",
    "import pandas as pd # for data analysis \n",
    "\n",
    "# let's also import the config we will need to interact with the Azure Open AI API\n",
    "\n",
    "from config import config_endpoint, config_key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac873b2-0cbe-4539-ab03-41b717a6eeab",
   "metadata": {},
   "source": [
    "# 1 - Load Product Insights\n",
    "\n",
    "Let's take a glimpse at the data we have. All this data has been validated with an LLM with a custom prompt and then reviewed by human validators. This explains why we have true and false positives and negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ea37f835-c3be-426d-832a-f2891a6e5769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feedback</th>\n",
       "      <th>Product Feedback and Limitations validation_status</th>\n",
       "      <th>Product Feedback and Limitations comment</th>\n",
       "      <th>Product Feedback and Limitations_human_review</th>\n",
       "      <th>Product Feedback and Limitations_human_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feedback and limitations - **Details ** Custom...</td>\n",
       "      <td>1</td>\n",
       "      <td>The feedback is valid as it specifically addre...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Valid concern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feedback and limitations Product Limitation \\n...</td>\n",
       "      <td>1</td>\n",
       "      <td>The feedback is specific as it refers to the d...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Feedback and limitations Customer appreciates ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The feedback is specific, mentioning the centr...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>Specific, actionable product feedback with cle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Feedback and limitations Customer have mention...</td>\n",
       "      <td>1</td>\n",
       "      <td>The feedback is specific, mentioning the activ...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feedback and limitations   After deleting the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>The feedback is specific, mentioning the issue...</td>\n",
       "      <td>Agree</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Feedback  \\\n",
       "0  Feedback and limitations - **Details ** Custom...   \n",
       "1  Feedback and limitations Product Limitation \\n...   \n",
       "2  Feedback and limitations Customer appreciates ...   \n",
       "3  Feedback and limitations Customer have mention...   \n",
       "4  Feedback and limitations   After deleting the ...   \n",
       "\n",
       "   Product Feedback and Limitations validation_status  \\\n",
       "0                                                  1    \n",
       "1                                                  1    \n",
       "2                                                  1    \n",
       "3                                                  1    \n",
       "4                                                  1    \n",
       "\n",
       "            Product Feedback and Limitations comment  \\\n",
       "0  The feedback is valid as it specifically addre...   \n",
       "1  The feedback is specific as it refers to the d...   \n",
       "2  The feedback is specific, mentioning the centr...   \n",
       "3  The feedback is specific, mentioning the activ...   \n",
       "4  The feedback is specific, mentioning the issue...   \n",
       "\n",
       "  Product Feedback and Limitations_human_review  \\\n",
       "0                                         Agree   \n",
       "1                                         Agree   \n",
       "2                                         Agree   \n",
       "3                                         Agree   \n",
       "4                                         Agree   \n",
       "\n",
       "      Product Feedback and Limitations_human_comment  \n",
       "0                                      Valid concern  \n",
       "1                                                NaN  \n",
       "2  Specific, actionable product feedback with cle...  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We load all the data \n",
    "\n",
    "true_positives = pd.read_csv('true_positive_sample.csv')\n",
    "true_negatives = pd.read_csv('true_negative_sample.csv')\n",
    "false_positives = pd.read_csv('false_positive_sample.csv')\n",
    "false_negatives = pd.read_csv('false_negative_sample.csv')\n",
    "\n",
    "# Now let's print one of the datasets to see its shape\n",
    "\n",
    "true_positives[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a622af27-5a45-4d55-92be-76c5b75a9a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "<>:4: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "/var/folders/xv/5lp8ff8s7j55zh1lrpr9ddkw0000gn/T/ipykernel_16247/3552424294.py:4: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [\"Product Feedback and Limitations validation_status\", \"Validation done by the LLM - 0 is invalid, 1 is valid\"]\n",
      "/var/folders/xv/5lp8ff8s7j55zh1lrpr9ddkw0000gn/T/ipykernel_16247/3552424294.py:4: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [\"Product Feedback and Limitations validation_status\", \"Validation done by the LLM - 0 is invalid, 1 is valid\"]\n",
      "/var/folders/xv/5lp8ff8s7j55zh1lrpr9ddkw0000gn/T/ipykernel_16247/3552424294.py:4: SyntaxWarning: list indices must be integers or slices, not tuple; perhaps you missed a comma?\n",
      "  [\"Product Feedback and Limitations validation_status\", \"Validation done by the LLM - 0 is invalid, 1 is valid\"]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Column explanation\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeedback\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRaw feedback notes captured by the agent and stored on Gigplus Trackers\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m----> 4\u001b[0m     \u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProduct Feedback and Limitations validation_status\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mValidation done by the LLM - 0 is invalid, 1 is valid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mProduct Feedback and Limitations comment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mExplanation provided by the LLM\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m      6\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct Feedback and Limitations_human_review\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHuman review, agreeing or disagreeing with the model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      7\u001b[0m     [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProduct Feedback and Limitations_human_comment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComment left by the human validator\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      8\u001b[0m \n\u001b[1;32m      9\u001b[0m ]\n\u001b[1;32m     10\u001b[0m column_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data, columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn Name\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExplanation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "# Column explanation\n",
    "data = [\n",
    "    [\"Feedback\", \"Raw feedback notes captured by the agent and stored on Gigplus Trackers\"],\n",
    "    [\"Product Feedback and Limitations validation_status\", \"Validation done by the LLM - 0 is invalid, 1 is valid\"],\n",
    "    [\"Product Feedback and Limitations comment\", \"Explanation provided by the LLM\"],\n",
    "    [\"Product Feedback and Limitations_human_review\", \"Human review, agreeing or disagreeing with the model\"],\n",
    "    [\"Product Feedback and Limitations_human_comment\", \"Comment left by the human validator\"]\n",
    "]\n",
    "column_data = pd.DataFrame(data, columns=[\"Column Name\", \"Explanation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ffb247-9a9f-4505-8b68-10aae8ac23a8",
   "metadata": {},
   "source": [
    "## 1.1 Baselining Performance\n",
    "\n",
    "Let's calculate Sensitivity, Recall and F1 for this dataset, which will give us target metrics to iterate on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f8dc1-de9e-4064-969c-74312b37e9fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
